I"3<p>HDD 하드디스크드라이브를 SCSI타입으로 1GB하나 추가한다.
해당 디스크를 5개의 파티션으로 분할한다(각각 100, 200, 200, 300, 200Mbyte)
각각의 파티션들을 xfs 파일시스템으로 포맷한 후 자동마운트시킨다.</p>

<p><img src="https://user-images.githubusercontent.com/39452092/82835762-f99ebb80-9eff-11ea-8c12-42c16b16ee90.png" alt="image" />
/kgitbank 하위의 5개 디렉토리에 각각 자동마운트 시킨 뒤에 마운트된 각각의 디렉토리 하위에 파일 및 디렉토리를 만들고 reboot 후 확인해보기 (일반마운트라면 재부팅 후에는 마운트가 자동해제가 되고 마운트상태에서 만들었던 파일들을 볼 수 없음. 그리고 다시 마운트를 시키면 만들었던 파일을 볼 수 있음)</p>

<p>자동 마운트 실습은 Client에서 진행</p>

<p>먼저 Client 머신이 꺼져있는 상태에서 Edit this virtual machine 클릭
하드웨어 장치창에서 Add버튼 클릭 후 Hard Disk 클릭 한 다음에 SCSI 타입으로 하드디스크를 추가한다.(용량은 1GB)
Client 머신을 킨 뒤 fdisk -l 로 장치가 인식되는지 확인 후 장치명을 확인한다. /dev/sdb 로 되어있을 것이다. fdisk /dev/sdb 로 sdb장치에 대한 파티션 생성창으로 진입한다.
n명령어로 파티션 생성 및 p로 Primary Partition 을 만들도록 하며 시작블록넘버는 자동으로 두고 크기만 +100M 로 한다. 이와 같은 과정을 1~3 파티션에 전부 동일하게 진행
그 다음에는 extended로 4번째 파티션 하나 만들고(이 때 남은 용량을 전부 Extended로 잡을 것이라면 그 용량은 추가기입하지 않고 그냥 엔터로만 넘기면 자동으로 남은 용량을 다 잡아준다) 그 안에 논리파티션으로 5, 6파티션을 생성한다.(이 논리파티션 번호는 자동으로 부여됨. 기입불가) 생성뒤에는 p로 생성된 파티션 확인한다. 마지막으로는 w명령어로 저장 후 종료를 꼭 하기. fdisk -l /dev/sdb 로 파티션분할 확인.
→ sector는 하드디스크의 기본 구성 최소단위(512byte)</p>

<p>이제 포맷으로 파일시스템을 생성해야하는데 명령어는 mkfs 이다.
mkfs -t xfs /dev/sdb1 또는 mkfs.xfs /dev/sdb1 과 같이 입력하면 된다.
이 과정을 1, 2, 3, 5, 6 파티션에 진행한다.
→ 포맷(파일시스템생성)여부 확인은 blkid로 확인할 수 있다. 원래 UUID확인용이기는 한데 포맷을 해야만 UUID가 나온다. (df나 mount 명령어는 마운트여부만 확인 가능)</p>

<p>mkdir 로 마운트포인트 디렉토리들을 생성한다.(mkdir -p 를 쓰면 편하다)
이후에 /etc/fstab파일을 vi로 열어 안에 아래와같이 내용을 기입한다.
“장치명 또는 UUID	마운트포인트	파일시스템	옵션	dump여부	부팅시점검여부”
만약 UUID값을 넣고 싶다면 명령어 실행결과를 현재 작업중인 텍스트파일에 집어넣는 명령어를 쓰자. → vi 편집상태에서 명령모드로 진입하여 ‘:줄수! 명령어’ (이 때 줄넘버는 내용을 삽입할 줄을 적어주면 된다. 공백상태로 존재하는 상태인 줄넘버값)
이제 저장 후 종료를 한다. 이 상태에서는 아직 마운트가 되지 않은 상황이다. 재부팅하면 마운트되기는 하지만 일단 ‘mount /dev/sdb숫자 /kgitbank/마운트디렉토리’ 로 재부팅없이 마운트 시킨다. 
→ mount -a 를 사용하면 마운트를 자동으로 해준다. /etc/fstab에 option값으로 넣었던 default안에 mount -a 입력시 auto mount 시켜주는 값이 켜져있음
⇒ 해당 디렉토리가 존재하지 않는 경우 이 명령어로 한번에 마운트시킬 수 없다.
fdisk -l 또는 df -h 또는 mount 명령어들로 확인
마운트된 디렉토리 내부에 파일 및 디렉토리를 만들고 reboot 뒤에도 마운트가 유지되어있는지, 또 마운트 뒤에 생성했던 파일이 남아있는지를 확인한다.</p>

<p>만약에 /etc/fstab에서 장치명을 잘못적는다면?
/dev/sdb2 → dev/sdb22로 바꾸고 
/dev/sdb3의 마운트포인트를 /kgitbank/window 를 /kgitbank/windows로 바꾸고 저장 후 종료를 해보자. 그리고 재부팅을 해보자</p>

<p>부팅을 하는동안 ESC를 눌러보면 어떤 작업을 하고있는지를 확인할 수 있다. 보면은 /dev/sdb22 장치를 계속 찾는다(최대 1분 30초까지)
→ 부팅하는동안 저널에 로그기록을 남긴다.</p>

<p><img src="https://user-images.githubusercontent.com/39452092/82835771-01f6f680-9f00-11ea-9677-407f28bbb94d.png" alt="image" />
부팅은 결국 되기는 한다. 응급모드로 부팅이 되긴 한다. (다만 이 때 systemctl get-default 를 쳐보면 여전히 multi-user mode이기는 하다. 부팅모드에서의 rescue mode와는 다른 듯 하다.)</p>

<p>/etc/fstab 파일을 설정 할 때 장치(또는 파티션), 옵션 등을 잘못 기입했을 때 정상적으로 부팅되지 않음(응급복구를 진행하여도 됨)</p>

<p>Give root password for maintenance 문구가 출력되면 관리자 비밀번호를 입력</p>

<p>1)	관리자 로그인
2)	/etc/fstab 파일을 편집
3)	잘못된 설정을 찾아 수정
4)	저장 후 종료
5)	reboot</p>

<p>일단은 /dev/sdb22 에 대해서만 원래대로 만들어놓고 저장 후 종료한다.</p>

<p>참고로 CentOS 6.x 에서는 3)번을 작업 할 때 기본적으로 /etc/fstab 파일이 ‘read-only’ 설정으로 되어있으므로 수정할 수 없었다. 느낌표를 해도 안됐었다. 
따라서 문서 편집기를 종료하고 아래의 명령어를 실행해야만 했었다.
mount -o(option) rw,remount /
최상위를 다시 마운트를 하는데 읽고쓰기 가능하도록 재마운트를 하겠다.
→ 우리가 쓰는 / 디렉토리는 사실 /dev/sda6 이다. 해당 장치를 재마운트하면서 모든 파일에 대해 읽기 쓰기가 가능하도록 재마운트하겠다는 것으로 보인다. 만약 umount / 또는 umount /dev/sda6 를 하면 어떻게 되려나..?</p>

<p>이제 일단 재부팅을 해보자. /dev/sdb2 에 대한 오류메시지는 이제 안뜬다. 근데 /dev/sdb3에 대한 마운트포인트가 잘못되었음에도 불구하고 정상부팅은 잘만된다. 
→ 마운트포인트와 dump값 및 점검값은 잘못써도 부팅은 잘만 된다. 장치명과 option값은 잘못되는경우 부팅이 안될 수 있다.</p>

<p>df -h를 해보면 /dev/sdb3가 /kgitbank/windows로 마운트되어있는 것을 볼 수 있다. 즉 마운트포인트를 자동으로 생성해준 것이다. 아까 만들었던 파일은 이제 /kgitbank/window에 있는게 아니라 /kgitbank/windows 에 있다.
CentOS 6.x에서는 이렇게 마운트포인트에 오타가 났었다면 마운트가 안되어있는 상태였음
그러나 CentOS 7 에서는 해당 디렉토리를 알아서 만들어준다. (재부팅할때 만들어줌)</p>

<p>/etc/fstab 설정 파일에서 마운트포인트 설정을 한 뒤에 시스템을 재부팅하면 마운트포인트를 생성하지 않았어도 자동으로 생성함 → 이러면 굳이 마운트포인트를 일일히 생성하고 mount시키거나 mount -a 시킬 필요 없이 재부팅만 하면 됨
(CentOS 6.x 에서는 자동으로 생성하지도 않음)</p>

<p>Client머신을 스냅샷으로 되돌리자. Snapshot_클라이언트_마지막</p>

<p>Server머신으로 들어가자.</p>

<p>NFS(Network File System)</p>
<ul>
  <li>파일 시스템 공유와 서버 자원 공유를 위해 1980년대 중반 SUN 마이크로 시스템즈(유닉스만든 곳)에서 개발</li>
  <li>디스크 공간 부족할 때 장치 가격이 비쌌으므로 이를 해결하기 위해서 만들어졌음 → 공유경제같은건가.. 부족한 부분에 대해 남는사람것을 쓰는 방식으로?</li>
  <li>오늘날 장치 성능이 좋아졌으므로 요즘엔 파일 공유 및 파일 서버를 위한 방법으로 사용(마치 예전에는 압축을 용량절약을 위해 썼었지만 요즘은 주로 여러 파일들을 하나로 묶어서 관리하기 위해 쓰듯)</li>
  <li>서버의 리소스(자원)를 클라이언트가 마치 자신의 리소스처럼 사용</li>
  <li>서버/클라이언트 구조로 이루어져 있으며 서버의 공유 파일 시스템을 클라이언트에서 마운트하여 사용</li>
  <li>상대방의 장치를 내것처럼 마운트하여 공유함</li>
  <li>보안은 취약함</li>
</ul>

<p>NFS 패키지 설치 유무를 확인 → rpm -qa|grep nfs
nfs-utils가 깔려있긴 하다. 이와 관련된 다른 도구도 있다. yum install nfs4-acl-tools를 설치하자(관련도구로서 꼭 설치할 필요는 없다)
설치 후 rpm -qa|grep nfs 로 설치 확인(패키지 명은 nfs로 시작)</p>

<p>NFS 를 쓰려면 또하나의 패키지가 반드시 필요하다.
rpcbind 패키지 설치 유무를 확인 → rpm -qa | grep rpcbind
패키지명은 rpcbind로 시작함
참고로 CentOS 5.x에서는 portmap이라는 패키지였음. Cent OS 6.x이후부터는 rpcbind라는 이름으로 바뀜
rpm -qa|grep portmap 이라고 치면 해당패키지는 존재하지 않는다. 그런데 yum install portmap 하면 rpcbind에 대한 메시지가 나온다.</p>

<p>portmap 즉, rpcbind란?
RPC(Remote Procedure Call : 원격 절차 호출)</p>
<ul>
  <li>별도의 원격제어를 코딩 없이 다른 주소 공간에서 함수를 실행할 수 있게 하는 프로세스 간 통신 기술</li>
  <li>NFS 서비스를 사용하기 위한 필수 통신 서비스</li>
  <li>클라이언트로부터 포트 요청이 있을 경우 새로운 포트를 할당해주며 mapping(변환)해주는 역할</li>
  <li>Web Server/FTP Server와 같이 특정 포트로 listening 하는 것이 아니라 portmapper 프로그램을 이용하여 네트워크 포트를 할당받게 됨</li>
  <li>portmapper 프로그램은 포트번호가 111번이며 listening 하다가 접속요청이 있으면 NFS Server에게 포트를 바꾸어 접속 연결을 시켜줌
즉! 징검다리 역할을 함</li>
</ul>

<p>telnet, ssh, vnc, ftp는 서버의 모든 공간을 헤집고 다닐 수 있었음
하지만 NFS는 서버의 정해진 곳으로만 통신을 할 수 있다. 
따라서 NFS는 일반적인 네트워크상태로 연결하는 것이 아니다. netstat으로 확인 불가능
별도의 통신확인 명령어가 존재한다.</p>

<p>포트번호
ftp는 20, 21
ssh 22
telnet 23
vnc 5900</p>

<p>portmapper는 111번 포트를 쓰는데 nfs 클라이언트가 접속요청을 하면 네트워크로부터 비어있는 포트를 부여받고 이를 NFS Server에게 부여한다. 따라서 NFS의 포트번호는 가변적이다.
서비스를 재시작하면 포트번호가 바뀐다. 따라서 수정내용을 적용하기 위한 별도의 명령어가 있다. 
→ 정리하자면..
NFS를 쓰려는 특정 클라이언트가 웹서버에 NFS를 쓰겠다고 요청을 보내면, 111번 포트를 통해 요청을 받은 서버의 RPC는 자신의 서버로부터 비어있는 포트를 찾는다. 찾은 후에는 해당 포트번호로 통신을 할 수 있도록 조치한다.</p>

<p>NFS 설정파일
/etc/exports</p>
<ul>
  <li>nfs의 설정파일</li>
</ul>

<p>vi로 열어보면 내용이 아무것도 없다.</p>
<ul>
  <li>기본적으로 아무런 내용이 없음</li>
</ul>

<p>설정방법
[share dir]	[access allow host/network]		(option)</p>

<p>첫번째 항목 : [share dir]
→ 공유할 디렉토리</p>

<p>두번째 항목 : [access allow host/network]
→ 접근을 허용할 호스트/네트워크 대역</p>

<p>예를 들어, 호스트를 설정할 것이라면
192.168.x.x (IP주소)를 적으면 된다.</p>

<p>네트워크 대역대로 설정할 것이라면
192.168.x.0(대표IP)/255.255.255.0(subnet mask) 또는 192.168.x.0/24(prefix)
→ 서브넷마스크값을 넣어주는 이유는 어디까지가 네트워크ID고 어디부터 호스트ID인지를 컴퓨터가 알 수 있도록 해주기 위해서인듯. “아 여기까지가 한 네트워크에 대한 ID값이고 이 뒷부분부터는 이 네트워크에 연결되어있는 각각의 호스트ID값이구나! 그러면 이 네트워크에 속해있는 모든 사용자에게는 전부 개방시켜놓도록 설정해놓았구나!” 처럼 알 수 있도록</p>

<p>이 설정은 서비스를 제공할 서버에서 설정해주면 되는 내용이다. 어떤 클라이언트가 내 서버의 NFS 시스템에 접근가능하게 할 것인지..</p>

<p>예를 들어, 모든 네트워크로 설정할 것이라면
*(all network) 를 쓰면 된다. → 0.0.0.0도 될 듯
⇒ 근데 설정파일들에 있어서, 모든 네트워크에 대해 *로 쓴 곳에 0.0.0.0 이라고 쓰면 될 때도 있지만 안될때도 있다고 한다. 직접 해봐야 한다고 하심</p>

<p>옵션부분에 대해서는 내일 설명 할 것</p>

<p><img src="https://user-images.githubusercontent.com/39452092/82835787-0a4f3180-9f00-11ea-8fef-77b35cf30b0a.png" alt="image" />
위와 같이 /etc/exports 에 주석값으로 작성한다. 아래에 쓰게 될 내용들이 무엇인지 구분할 수 있도록 Column 작성한 것임</p>
:ET